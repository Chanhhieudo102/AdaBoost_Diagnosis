{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35103b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:22.583947Z",
     "iopub.status.busy": "2025-11-24T07:54:22.583742Z",
     "iopub.status.idle": "2025-11-24T07:54:28.571592Z",
     "shell.execute_reply": "2025-11-24T07:54:28.570588Z"
    },
    "papermill": {
     "duration": 5.993162,
     "end_time": "2025-11-24T07:54:28.572911",
     "exception": false,
     "start_time": "2025-11-24T07:54:22.579749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EN lines: 133317\n",
      "TRAIN VI lines: 133317\n",
      "TEST  EN lines: 1268\n",
      "TEST  VI lines: 1268\n",
      "✅ Train dataset khớp số dòng!\n",
      "✅ Test dataset khớp số dòng!\n",
      "\n",
      "--- SAMPLE TRAIN PAIRS ---\n",
      "[EN] Rachel Pike : The science behind a climate headline\n",
      "[VI] Khoa học đằng sau một tiêu đề về khí hậu\n",
      "\n",
      "[EN] In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
      "[VI] Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
      "\n",
      "[EN] I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "[VI] Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "\n",
      "\n",
      "--- SAMPLE TEST PAIRS ---\n",
      "[EN] When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;\n",
      "[VI] Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\n",
      "\n",
      "[EN] And I was very proud .\n",
      "[VI] Tôi đã rất tự hào về đất nước tôi .\n",
      "\n",
      "[EN] In school , we spent a lot of time studying the history of Kim Il-Sung , but we never learned much about the outside world , except that America , South Korea , Japan are the enemies .\n",
      "[VI] Ở trường , chúng tôi dành rất nhiều thời gian để học về cuộc đời của chủ tịch Kim II- Sung , nhưng lại không học nhiều về thế giới bên ngoài , ngoại trừ việc Hoa Kỳ , Hàn Quốc và Nhật Bản là kẻ thù của chúng tôi .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "train_en_path = \"/kaggle/input/en-vi-ds/data/train.en\"\n",
    "train_vi_path = \"/kaggle/input/en-vi-ds/data/train.vi\"\n",
    "test_en_path  = \"/kaggle/input/en-vi-ds/data/tst2013.en\"\n",
    "test_vi_path  = \"/kaggle/input/en-vi-ds/data/tst2013.vi\"\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "\n",
    "train_en = load_file(train_en_path)\n",
    "train_vi = load_file(train_vi_path)\n",
    "test_en  = load_file(test_en_path)\n",
    "test_vi  = load_file(test_vi_path)\n",
    "\n",
    "print(\"TRAIN EN lines:\", len(train_en))\n",
    "print(\"TRAIN VI lines:\", len(train_vi))\n",
    "print(\"TEST  EN lines:\", len(test_en))\n",
    "print(\"TEST  VI lines:\", len(test_vi))\n",
    "\n",
    "if len(train_en) != len(train_vi):\n",
    "    print(\"❌ Lỗi: train.en và train.vi không khớp số dòng!\")\n",
    "else:\n",
    "    print(\"✅ Train dataset khớp số dòng!\")\n",
    "\n",
    "if len(test_en) != len(test_vi):\n",
    "    print(\"❌ Lỗi: test.en và test.vi không khớp số dòng!\")\n",
    "else:\n",
    "    print(\"✅ Test dataset khớp số dòng!\")\n",
    "\n",
    "# In thử 3 cặp đầu tiên để xem có đúng là song ngữ\n",
    "print(\"\\n--- SAMPLE TRAIN PAIRS ---\")\n",
    "for i in range(3):\n",
    "    print(f\"[EN] {train_en[i]}\")\n",
    "    print(f\"[VI] {train_vi[i]}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n--- SAMPLE TEST PAIRS ---\")\n",
    "for i in range(3):\n",
    "    print(f\"[EN] {test_en[i]}\")\n",
    "    print(f\"[VI] {test_vi[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e1f274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.579615Z",
     "iopub.status.busy": "2025-11-24T07:54:28.578947Z",
     "iopub.status.idle": "2025-11-24T07:54:28.582908Z",
     "shell.execute_reply": "2025-11-24T07:54:28.582199Z"
    },
    "papermill": {
     "duration": 0.008227,
     "end_time": "2025-11-24T07:54:28.583992",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.575765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abb5cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.590290Z",
     "iopub.status.busy": "2025-11-24T07:54:28.589743Z",
     "iopub.status.idle": "2025-11-24T07:54:28.601915Z",
     "shell.execute_reply": "2025-11-24T07:54:28.601359Z"
    },
    "papermill": {
     "duration": 0.016383,
     "end_time": "2025-11-24T07:54:28.602925",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.586542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texts, min_freq=2):\n",
    "        self.word2idx = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
    "        self.idx2word = {v:k for k,v in self.word2idx.items()}\n",
    "        self.build_vocab(texts, min_freq)\n",
    "\n",
    "    def build_vocab(self, texts, min_freq):\n",
    "        counter = Counter()\n",
    "        for line in texts:\n",
    "            counter.update(line.lower().strip().split())\n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.word2idx.get(tok, 3) for tok in text.lower().strip().split()]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            if i == 2: break      # stop at <eos>\n",
    "            if i > 3: words.append(self.idx2word.get(i, \"<unk>\"))\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f84a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.608490Z",
     "iopub.status.busy": "2025-11-24T07:54:28.608229Z",
     "iopub.status.idle": "2025-11-24T07:54:28.612634Z",
     "shell.execute_reply": "2025-11-24T07:54:28.611958Z"
    },
    "papermill": {
     "duration": 0.008456,
     "end_time": "2025-11-24T07:54:28.613765",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.605309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src, trg, tok_src, tok_trg):\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "        self.tok_src = tok_src\n",
    "        self.tok_trg = tok_trg\n",
    "\n",
    "    def __len__(self): return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = [1] + self.tok_src.encode(self.src[idx]) + [2]   # <sos> ... <eos>\n",
    "        t = [1] + self.tok_trg.encode(self.trg[idx]) + [2]\n",
    "        return torch.tensor(s), torch.tensor(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a325b5b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.620512Z",
     "iopub.status.busy": "2025-11-24T07:54:28.620301Z",
     "iopub.status.idle": "2025-11-24T07:54:28.623715Z",
     "shell.execute_reply": "2025-11-24T07:54:28.623189Z"
    },
    "papermill": {
     "duration": 0.008682,
     "end_time": "2025-11-24T07:54:28.624791",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.616109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, pad_idx=0):\n",
    "    src, trg = zip(*batch)\n",
    "    src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_idx)\n",
    "    trg = nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=pad_idx)\n",
    "    return src, trg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df36ac99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.630396Z",
     "iopub.status.busy": "2025-11-24T07:54:28.630220Z",
     "iopub.status.idle": "2025-11-24T07:54:28.634773Z",
     "shell.execute_reply": "2025-11-24T07:54:28.634262Z"
    },
    "papermill": {
     "duration": 0.008428,
     "end_time": "2025-11-24T07:54:28.635767",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.627339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000)/d_model))\n",
    "        pe[:,0::2] = torch.sin(pos*div)\n",
    "        pe[:,1::2] = torch.cos(pos*div)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbf524d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.642195Z",
     "iopub.status.busy": "2025-11-24T07:54:28.642019Z",
     "iopub.status.idle": "2025-11-24T07:54:28.647328Z",
     "shell.execute_reply": "2025-11-24T07:54:28.646717Z"
    },
    "papermill": {
     "duration": 0.009649,
     "end_time": "2025-11-24T07:54:28.648287",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.638638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model=256, nhead=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model)\n",
    "        self.trg_emb = nn.Embedding(trg_vocab, d_model)\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, trg_vocab)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src = self.pos(self.src_emb(src))\n",
    "        trg = self.pos(self.trg_emb(trg))\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(trg.size(1)).to(trg.device)\n",
    "        out = self.transformer(src, trg, tgt_mask=tgt_mask)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b589f664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.653950Z",
     "iopub.status.busy": "2025-11-24T07:54:28.653774Z",
     "iopub.status.idle": "2025-11-24T07:54:28.659704Z",
     "shell.execute_reply": "2025-11-24T07:54:28.659226Z"
    },
    "papermill": {
     "duration": 0.010197,
     "end_time": "2025-11-24T07:54:28.660781",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.650584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, opt, loss_fn, device, epochs=10):\n",
    "    best = 999\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        for src, trg in train_loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            opt.zero_grad()\n",
    "            out = model(src, trg[:,:-1])\n",
    "            loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:,1:].reshape(-1))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "\n",
    "        # VAL\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for src, trg in val_loader:\n",
    "                src, trg = src.to(device), trg.to(device)\n",
    "                out = model(src, trg[:,:-1])\n",
    "                loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:,1:].reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} | Train {total/len(train_loader):.4f} | Val {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "        if val_loss < best:\n",
    "            best = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            print(\"✔ Saved best model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64db03a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.666215Z",
     "iopub.status.busy": "2025-11-24T07:54:28.665819Z",
     "iopub.status.idle": "2025-11-24T07:54:28.670196Z",
     "shell.execute_reply": "2025-11-24T07:54:28.669686Z"
    },
    "papermill": {
     "duration": 0.008065,
     "end_time": "2025-11-24T07:54:28.671131",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.663066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(model, text, tok_src, tok_trg, device, max_len=60):\n",
    "    model.eval()\n",
    "    src = [1] + tok_src.encode(text) + [2]\n",
    "    src = torch.tensor(src).unsqueeze(0).to(device)\n",
    "\n",
    "    trg = torch.tensor([[1]]).to(device)  # <sos>\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        out = model(src, trg)\n",
    "        next_tok = out[0, -1].argmax().item()\n",
    "        trg = torch.cat([trg, torch.tensor([[next_tok]]).to(device)], dim=1)\n",
    "        if next_tok == 2: break\n",
    "\n",
    "    return tok_trg.decode(trg[0].tolist()[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d936491f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.676914Z",
     "iopub.status.busy": "2025-11-24T07:54:28.676310Z",
     "iopub.status.idle": "2025-11-24T07:54:28.680852Z",
     "shell.execute_reply": "2025-11-24T07:54:28.680181Z"
    },
    "papermill": {
     "duration": 0.008517,
     "end_time": "2025-11-24T07:54:28.681919",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.673402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=50):\n",
    "    model.eval()\n",
    "    total_bleu = 0\n",
    "    for i in range(n):\n",
    "        pred = translate(model, test_en[i], tok_src, tok_trg, device)\n",
    "        bleu = sentence_bleu([test_vi[i].split()], pred.split())\n",
    "        total_bleu += bleu\n",
    "        print(f\"\\nEN: {test_en[i]}\")\n",
    "        print(f\"GT: {test_vi[i]}\")\n",
    "        print(f\"PR: {pred}\")\n",
    "        print(f\"BLEU: {bleu:.4f}\")\n",
    "\n",
    "    print(\"\\nAVERAGE BLEU =\", total_bleu/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2817637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.687564Z",
     "iopub.status.busy": "2025-11-24T07:54:28.687063Z",
     "iopub.status.idle": "2025-11-24T07:54:28.943289Z",
     "shell.execute_reply": "2025-11-24T07:54:28.942750Z"
    },
    "papermill": {
     "duration": 0.260372,
     "end_time": "2025-11-24T07:54:28.944616",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.684244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_en = open(\"/kaggle/input/en-vi-ds/data/train.en\").read().splitlines()\n",
    "train_vi = open(\"/kaggle/input/en-vi-ds/data/train.vi\").read().splitlines()\n",
    "test_en  = open(\"/kaggle/input/en-vi-ds/data/tst2013.en\").read().splitlines()\n",
    "test_vi  = open(\"/kaggle/input/en-vi-ds/data/tst2013.vi\").read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c207423b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:28.950606Z",
     "iopub.status.busy": "2025-11-24T07:54:28.950172Z",
     "iopub.status.idle": "2025-11-24T07:54:30.145751Z",
     "shell.execute_reply": "2025-11-24T07:54:30.144948Z"
    },
    "papermill": {
     "duration": 1.199934,
     "end_time": "2025-11-24T07:54:30.147102",
     "exception": false,
     "start_time": "2025-11-24T07:54:28.947168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tok_src = Tokenizer(train_en)\n",
    "tok_trg = Tokenizer(train_vi)\n",
    "\n",
    "dataset = TranslationDataset(train_en, train_vi, tok_src, tok_trg)\n",
    "\n",
    "train_len = int(0.9 * len(dataset))\n",
    "val_len = len(dataset) - train_len\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_set, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede8d47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:54:30.153293Z",
     "iopub.status.busy": "2025-11-24T07:54:30.152816Z",
     "iopub.status.idle": "2025-11-24T08:46:33.671679Z",
     "shell.execute_reply": "2025-11-24T08:46:33.670876Z"
    },
    "papermill": {
     "duration": 3123.525567,
     "end_time": "2025-11-24T08:46:33.675210",
     "exception": false,
     "start_time": "2025-11-24T07:54:30.149643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train 4.4464 | Val 3.7184\n",
      "Epoch 2/10 | Train 3.5407 | Val 3.2697\n",
      "Epoch 3/10 | Train 3.1657 | Val 2.9874\n",
      "Epoch 4/10 | Train 2.8958 | Val 2.7900\n",
      "Epoch 5/10 | Train 2.6951 | Val 2.6387\n",
      "Epoch 6/10 | Train 2.5389 | Val 2.5478\n",
      "Epoch 7/10 | Train 2.4152 | Val 2.4673\n",
      "Epoch 8/10 | Train 2.3132 | Val 2.4056\n",
      "Epoch 9/10 | Train 2.2262 | Val 2.3623\n",
      "Epoch 10/10 | Train 2.1532 | Val 2.3302\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerModel(len(tok_src.word2idx), len(tok_trg.word2idx)).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "train_model(model, train_loader, val_loader, opt, loss_fn, device, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d49568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:46:33.682590Z",
     "iopub.status.busy": "2025-11-24T08:46:33.682225Z",
     "iopub.status.idle": "2025-11-24T08:46:33.871045Z",
     "shell.execute_reply": "2025-11-24T08:46:33.870469Z"
    },
    "papermill": {
     "duration": 0.193476,
     "end_time": "2025-11-24T08:46:33.872157",
     "exception": false,
     "start_time": "2025-11-24T08:46:33.678681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi thích máy\n",
      "thời tiết ngày nay thời tiết là thời tiết .\n",
      "anh ta là một người rất thông minh .\n"
     ]
    }
   ],
   "source": [
    "print(translate(model, \"I love machine learning.\", tok_src, tok_trg, device))\n",
    "print(translate(model, \"Today the weather is nice.\", tok_src, tok_trg, device))\n",
    "print(translate(model, \"He is a very smart engineer.\", tok_src, tok_trg, device))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8761788,
     "sourceId": 13767258,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 505429,
     "modelInstanceId": 489996,
     "sourceId": 649510,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3136.341376,
   "end_time": "2025-11-24T08:46:35.394344",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-24T07:54:19.052968",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
