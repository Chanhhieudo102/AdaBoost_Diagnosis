{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13767258,"sourceType":"datasetVersion","datasetId":8761788},{"sourceId":649510,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":489996,"modelId":505429}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport random\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# -------------------------\n# Seed (deterministic for reproducibility)\n# -------------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\n# ==============================\n# 2️⃣ LOAD DỮ LIỆU\n# ==============================\ntrain_en = open(\"/kaggle/input/en-vi-ds/data/train.en\", \"r\", encoding=\"utf-8\").read().splitlines()\ntrain_vi = open(\"/kaggle/input/en-vi-ds/data/train.vi\", \"r\", encoding=\"utf-8\").read().splitlines()\ntest_en  = open(\"/kaggle/input/en-vi-ds/data/tst2013.en\", \"r\", encoding=\"utf-8\").read().splitlines()\ntest_vi  = open(\"/kaggle/input/en-vi-ds/data/tst2013.vi\", \"r\", encoding=\"utf-8\").read().splitlines()\n\nprint(\"Train:\", len(train_en), \"Test:\", len(test_en))\n\n# ==============================\n# 3️⃣ TOKENIZER (min_freq=1 to avoid too many <unk>)\n# ==============================\nclass Tokenizer:\n    def __init__(self, texts, min_freq=1):\n        self.word2idx = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"<unk>\":3}\n        self.idx2word = {v:k for k,v in self.word2idx.items()}\n        self.build_vocab(texts, min_freq)\n\n    def build_vocab(self, texts, min_freq):\n        counter = Counter()\n        for line in texts:\n            counter.update(line.strip().lower().split())\n        for word, freq in counter.items():\n            if freq >= min_freq and word not in self.word2idx:\n                idx = len(self.word2idx)\n                self.word2idx[word] = idx\n                self.idx2word[idx] = word\n\n    def encode(self, text):\n        # returns list of token ids (no <sos>/<eos> here)\n        return [self.word2idx.get(tok, self.word2idx[\"<unk>\"]) for tok in text.strip().lower().split()]\n\n    def decode(self, ids):\n        words = []\n        for i in ids:\n            if i == self.word2idx[\"<eos>\"]:\n                break\n            if i <= 3:  # 0-3 are special tokens or pad/unk/sos/eos: skip except unk? keep readable\n                if i == self.word2idx[\"<unk>\"]:\n                    words.append(\"<unk>\")\n                continue\n            words.append(self.idx2word.get(i, \"<unk>\"))\n        return \" \".join(words)\n\ntok_src = Tokenizer(train_en, min_freq=1)\ntok_trg = Tokenizer(train_vi, min_freq=1)\n\n# ==============================\n# 4️⃣ DATASET + collate\n# ==============================\nclass TranslationDataset(Dataset):\n    def __init__(self, src, trg, tok_src, tok_trg):\n        self.src = src\n        self.trg = trg\n        self.tok_src = tok_src\n        self.tok_trg = tok_trg\n\n    def __len__(self): return len(self.src)\n\n    def __getitem__(self, idx):\n        s = [self.tok_src.word2idx[\"<sos>\"]] + self.tok_src.encode(self.src[idx]) + [self.tok_src.word2idx[\"<eos>\"]]\n        t = [self.tok_trg.word2idx[\"<sos>\"]] + self.tok_trg.encode(self.trg[idx]) + [self.tok_trg.word2idx[\"<eos>\"]]\n        return torch.tensor(s, dtype=torch.long), torch.tensor(t, dtype=torch.long)\n\ndef collate_fn(batch, pad_idx=0):\n    src, trg = zip(*batch)\n    src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_idx)\n    trg = nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=pad_idx)\n    return src, trg\n\ndataset = TranslationDataset(train_en, train_vi, tok_src, tok_trg)\ntrain_len = int(0.9 * len(dataset))\nval_len = len(dataset) - train_len\ntrain_set, val_set = random_split(dataset, [train_len, val_len])\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_loader   = DataLoader(val_set, batch_size=32, shuffle=False, collate_fn=collate_fn)\n\n# ==============================\n# 5️⃣ POS ENCODING\n# ==============================\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float) * -(math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer('pe', pe.unsqueeze(0))  # registered buffer -> moves with .to(device)\n\n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]\n\n# ==============================\n# 6️⃣ TRANSFORMER MODEL (with weight tying & device-safety)\n# ==============================\nclass TransformerModel(nn.Module):\n    def __init__(self, src_vocab, trg_vocab, d_model=256, nhead=4, num_layers=3, pad_idx=0, dropout=0.1):\n        super().__init__()\n        self.pad_idx = pad_idx\n        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=pad_idx)\n        self.trg_emb = nn.Embedding(trg_vocab, d_model, padding_idx=pad_idx)\n        self.pos = PositionalEncoding(d_model)\n        self.transformer = nn.Transformer(\n            d_model=d_model, nhead=nhead,\n            num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.fc = nn.Linear(d_model, trg_vocab)\n        # weight tying (output projection shares embedding weight)\n        self.fc.weight = self.trg_emb.weight\n\n    def forward(self, src, trg):\n        # src: (B, S), trg: (B, T)\n        device = src.device\n        src_key_padding_mask = (src == self.pad_idx)  # (B, S)\n        trg_key_padding_mask = (trg == self.pad_idx)  # (B, T)\n        # subsequent mask for target (T, T)\n        T = trg.size(1)\n        trg_mask = nn.Transformer.generate_square_subsequent_mask(T).to(device)\n\n        src_emb = self.pos(self.src_emb(src))  # (B, S, d_model)\n        trg_emb = self.pos(self.trg_emb(trg))  # (B, T, d_model)\n\n        out = self.transformer(\n            src_emb, trg_emb,\n            tgt_mask=trg_mask,\n            src_key_padding_mask=src_key_padding_mask,\n            tgt_key_padding_mask=trg_key_padding_mask,\n            memory_key_padding_mask=src_key_padding_mask\n        )  # (B, T, d_model)\n        return self.fc(out)  # (B, T, trg_vocab)\n\n# ==============================\n# 7️⃣ TRAINING FUNCTION (improvements: lr scheduler, AdamW, save best)\n# ==============================\ndef train_model(model, train_loader, val_loader, device, epochs=10, lr=3e-4, pad_idx=0):\n    model.to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_idx)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=1, factor=0.5, verbose=True)\n\n    best_val = float('inf')\n    for ep in range(1, epochs+1):\n        model.train()\n        total_loss = 0.0\n        for src, trg in train_loader:\n            src, trg = src.to(device), trg.to(device)\n            opt.zero_grad()\n            # teacher forcing: feed trg tokens except last as input\n            out = model(src, trg[:, :-1])  # predict next token for each pos\n            # out: (B, T-1, V) -> flatten\n            loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:, 1:].reshape(-1))\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            opt.step()\n            total_loss += loss.item()\n\n        avg_train = total_loss / len(train_loader)\n\n        # validation\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for src, trg in val_loader:\n                src, trg = src.to(device), trg.to(device)\n                out = model(src, trg[:, :-1])\n                loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:, 1:].reshape(-1))\n                val_loss += loss.item()\n        avg_val = val_loss / len(val_loader)\n\n        scheduler.step(avg_val)\n\n        print(f\"Epoch {ep}/{epochs} | Train {avg_train:.4f} | Val {avg_val:.4f}\")\n\n        if avg_val < best_val:\n            best_val = avg_val\n            torch.save({\n                'model_state': model.state_dict(),\n                'tok_src': tok_src.word2idx,\n                'tok_trg': tok_trg.word2idx\n            }, \"best_model.pt\")\n            print(\"✔ Saved best model!\")\n\n# ==============================\n# 8️⃣ TRANSLATE (greedy) - improved (stop when <eos>, limit length)\n# ==============================\ndef translate(model, text, tok_src, tok_trg, device, max_len=60):\n    model.eval()\n    src = [tok_src.word2idx[\"<sos>\"]] + tok_src.encode(text) + [tok_src.word2idx[\"<eos>\"]]\n    src = torch.tensor(src, dtype=torch.long).unsqueeze(0).to(device)  # (1, S)\n    trg = torch.tensor([[tok_trg.word2idx[\"<sos>\"]]], dtype=torch.long).to(device)  # (1,1)\n    with torch.no_grad():\n        for _ in range(max_len):\n            out = model(src, trg)  # (1, T, V)\n            next_tok = out[0, -1].argmax().item()\n            trg = torch.cat([trg, torch.tensor([[next_tok]], device=device)], dim=1)\n            if next_tok == tok_trg.word2idx[\"<eos>\"]:\n                break\n    # strip leading <sos> when decoding\n    return tok_trg.decode(trg[0].tolist()[1:])\n\n# ==============================\n# 9️⃣ EVALUATE BLEU (use smoothing)\n# ==============================\ndef evaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=50):\n    model.eval()\n    total_bleu = 0\n    smooth = SmoothingFunction().method1\n    n = min(n, len(test_en))\n    for i in range(n):\n        pred = translate(model, test_en[i], tok_src, tok_trg, device)\n        bleu = sentence_bleu([test_vi[i].split()], pred.split(), smoothing_function=smooth)\n        total_bleu += bleu\n        if i < 10:  # print a few examples\n            print(f\"\\nEN: {test_en[i]}\")\n            print(f\"GT: {test_vi[i]}\")\n            print(f\"PR: {pred}\")\n            print(f\"BLEU: {bleu:.4f}\")\n\n    print(\"\\nAVERAGE BLEU =\", total_bleu / n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:06:15.405114Z","iopub.execute_input":"2025-11-25T03:06:15.405391Z","iopub.status.idle":"2025-11-25T03:06:22.154588Z","shell.execute_reply.started":"2025-11-25T03:06:15.405347Z","shell.execute_reply":"2025-11-25T03:06:22.153619Z"}},"outputs":[{"name":"stdout","text":"Train: 133317 Test: 1268\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==============================\n# RUN (example)\n# ==============================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TransformerModel(len(tok_src.word2idx), len(tok_trg.word2idx), d_model=256, nhead=4, num_layers=3, pad_idx=tok_src.word2idx[\"<pad>\"])\ntrain_model(model, train_loader, val_loader, device, epochs=10, lr=3e-4, pad_idx=tok_src.word2idx[\"<pad>\"])\n# then evaluate\n# evaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T03:06:49.022201Z","iopub.execute_input":"2025-11-25T03:06:49.022912Z","iopub.status.idle":"2025-11-25T04:14:45.435689Z","shell.execute_reply.started":"2025-11-25T03:06:49.022882Z","shell.execute_reply":"2025-11-25T04:14:45.434811Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 | Train 7.0318 | Val 4.2925\n✔ Saved best model!\nEpoch 2/10 | Train 3.9963 | Val 3.5733\n✔ Saved best model!\nEpoch 3/10 | Train 3.4682 | Val 3.2209\n✔ Saved best model!\nEpoch 4/10 | Train 3.1569 | Val 2.9700\n✔ Saved best model!\nEpoch 5/10 | Train 2.9423 | Val 2.8181\n✔ Saved best model!\nEpoch 6/10 | Train 2.7779 | Val 2.7071\n✔ Saved best model!\nEpoch 7/10 | Train 2.6488 | Val 2.6135\n✔ Saved best model!\nEpoch 8/10 | Train 2.5431 | Val 2.5541\n✔ Saved best model!\nEpoch 9/10 | Train 2.4529 | Val 2.4985\n✔ Saved best model!\nEpoch 10/10 | Train 2.3776 | Val 2.4460\n✔ Saved best model!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\nevaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:21:36.137531Z","iopub.execute_input":"2025-11-25T04:21:36.138224Z","iopub.status.idle":"2025-11-25T04:21:37.954516Z","shell.execute_reply.started":"2025-11-25T04:21:36.138200Z","shell.execute_reply":"2025-11-25T04:21:37.953883Z"}},"outputs":[{"name":"stdout","text":"\nEN: When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;\nGT: Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\nPR: khi tôi nhỏ , tôi nghĩ đất nước tôi là một đất nước tốt nhất trên hành tinh , và tôi lớn lên hát &quot; không có gì để giải phóng . &quot;\nBLEU: 0.1671\n\nEN: And I was very proud .\nGT: Tôi đã rất tự hào về đất nước tôi .\nPR: và tôi rất tự hào .\nBLEU: 0.1179\n\nEN: In school , we spent a lot of time studying the history of Kim Il-Sung , but we never learned much about the outside world , except that America , South Korea , Japan are the enemies .\nGT: Ở trường , chúng tôi dành rất nhiều thời gian để học về cuộc đời của chủ tịch Kim II- Sung , nhưng lại không học nhiều về thế giới bên ngoài , ngoại trừ việc Hoa Kỳ , Hàn Quốc và Nhật Bản là kẻ thù của chúng tôi .\nPR: ở trường , chúng tôi dành rất nhiều thời gian nghiên cứu lịch sử của những con khỉ , nhưng chúng tôi không bao giờ học được nhiều về thế giới bên ngoài , ngoại trừ nước mỹ , hàn quốc , hàn quốc là những kẻ thù .\nBLEU: 0.3556\n\nEN: Although I often wondered about the outside world , I thought I would spend my entire life in North Korea , until everything suddenly changed .\nGT: Mặc dù tôi đã từng tự hỏi không biết thế giới bên ngoài kia như thế nào , nhưng tôi vẫn nghĩ rằng mình sẽ sống cả cuộc đời ở BắcTriều Tiên , cho tới khi tất cả mọi thứ đột nhiên thay đổi .\nPR: mặc dù tôi thường tự hỏi về thế giới bên ngoài , tôi nghĩ rằng tôi sẽ dành toàn bộ cuộc sống ở bắc triều tiên , cho đến khi mọi thứ đã thay đổi .\nBLEU: 0.1182\n\nEN: When I was seven years old , I saw my first public execution , but I thought my life in North Korea was normal .\nGT: Khi tôi lên 7 , tôi chứng kiến cảnh người ta xử bắn công khai lần đầu tiên trong đời , nhưng tôi vẫn nghĩ cuộc sống của mình ở đây là hoàn toàn bình thường .\nPR: khi tôi bảy tuổi , tôi thấy sự xuất bản đầu tiên của tôi công chúng tôi đã nghĩ cuộc sống ở bắc triều tiên là bình thường .\nBLEU: 0.0578\n\nEN: My family was not poor , and myself , I had never experienced hunger .\nGT: Gia đình của tôi không nghèo , và bản thân tôi thì chưa từng phải chịu đói .\nPR: gia đình tôi không nghèo , và tôi chưa bao giờ trải qua nạn đói .\nBLEU: 0.2541\n\nEN: But one day , in 1995 , my mom brought home a letter from a coworker &apos;s sister .\nGT: Nhưng vào một ngày của năm 1995 , mẹ tôi mang về nhà một lá thư từ một người chị em cùng chỗ làm với mẹ .\nPR: nhưng một ngày , năm 1995 , mẹ tôi mang về một lá thư từ một chị gái của một người chị .\nBLEU: 0.4150\n\nEN: It read , &quot; When you read this , all five family members will not exist in this world , because we haven &apos;t eaten for the past two weeks .\nGT: Trong đó có viết : Khi chị đọc được những dòng này thì cả gia đình 5 người của em đã không còn trên cõi đời này nữa , bởi vì cả nhà em đã không có gì để ăn trong hai tuần .\nPR: nó đọc , &quot; khi bạn đọc nó , tất cả năm thành viên trong thế giới này , bởi vì chúng ta chưa ăn trong hai tuần .\nBLEU: 0.1040\n\nEN: We are lying on the floor together , and our bodies are so weak we are ready to die . &quot;\nGT: Tất cả cùng nằm trên sàn , và cơ thể chúng tôi yếu đến có thể cảm thấy như cái chết đang đến rất gần .\nPR: chúng ta đang nằm trên sàn nhà , và cơ thể chúng ta rất yếu kém chúng ta đã sẵn sàng chết . &quot;\nBLEU: 0.2046\n\nEN: I was so shocked .\nGT: Tôi đã bị sốc .\nPR: tôi đã rất sốc .\nBLEU: 0.1257\n\nAVERAGE BLEU = 0.19199909747232277\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"sent = \"See you again\"\nprint(translate(model, sent, tok_src, tok_trg, device))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:26:43.044334Z","iopub.execute_input":"2025-11-25T04:26:43.045076Z","iopub.status.idle":"2025-11-25T04:26:43.086215Z","shell.execute_reply.started":"2025-11-25T04:26:43.045050Z","shell.execute_reply":"2025-11-25T04:26:43.085607Z"}},"outputs":[{"name":"stdout","text":"bạn thấy lại .\n","output_type":"stream"}],"execution_count":8}]}