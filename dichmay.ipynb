{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3595a149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:56:36.548550Z",
     "iopub.status.busy": "2025-11-25T05:56:36.548276Z",
     "iopub.status.idle": "2025-11-25T05:56:44.136514Z",
     "shell.execute_reply": "2025-11-25T05:56:44.135687Z"
    },
    "papermill": {
     "duration": 7.593221,
     "end_time": "2025-11-25T05:56:44.137907",
     "exception": false,
     "start_time": "2025-11-25T05:56:36.544686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 133317 Test: 1268\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# -------------------------\n",
    "# Seed (deterministic for reproducibility)\n",
    "# -------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ==============================\n",
    "# 2️⃣ LOAD DỮ LIỆU\n",
    "# ==============================\n",
    "train_en = open(\"/kaggle/input/en-vi-ds/data/train.en\", \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "train_vi = open(\"/kaggle/input/en-vi-ds/data/train.vi\", \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "test_en  = open(\"/kaggle/input/en-vi-ds/data/tst2013.en\", \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "test_vi  = open(\"/kaggle/input/en-vi-ds/data/tst2013.vi\", \"r\", encoding=\"utf-8\").read().splitlines()\n",
    "\n",
    "print(\"Train:\", len(train_en), \"Test:\", len(test_en))\n",
    "\n",
    "# ==============================\n",
    "# 3️⃣ TOKENIZER (min_freq=1 to avoid too many <unk>)\n",
    "# ==============================\n",
    "class Tokenizer:\n",
    "    def __init__(self, texts, min_freq=1):\n",
    "        self.word2idx = {\"<pad>\":0, \"<sos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
    "        self.idx2word = {v:k for k,v in self.word2idx.items()}\n",
    "        self.build_vocab(texts, min_freq)\n",
    "\n",
    "    def build_vocab(self, texts, min_freq):\n",
    "        counter = Counter()\n",
    "        for line in texts:\n",
    "            counter.update(line.strip().lower().split())\n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq and word not in self.word2idx:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "\n",
    "    def encode(self, text):\n",
    "        # returns list of token ids (no <sos>/<eos> here)\n",
    "        return [self.word2idx.get(tok, self.word2idx[\"<unk>\"]) for tok in text.strip().lower().split()]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            if i == self.word2idx[\"<eos>\"]:\n",
    "                break\n",
    "            if i <= 3:  # 0-3 are special tokens or pad/unk/sos/eos: skip except unk? keep readable\n",
    "                if i == self.word2idx[\"<unk>\"]:\n",
    "                    words.append(\"<unk>\")\n",
    "                continue\n",
    "            words.append(self.idx2word.get(i, \"<unk>\"))\n",
    "        return \" \".join(words)\n",
    "\n",
    "tok_src = Tokenizer(train_en, min_freq=1)\n",
    "tok_trg = Tokenizer(train_vi, min_freq=1)\n",
    "\n",
    "# ==============================\n",
    "# 4️⃣ DATASET + collate\n",
    "# ==============================\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src, trg, tok_src, tok_trg):\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "        self.tok_src = tok_src\n",
    "        self.tok_trg = tok_trg\n",
    "\n",
    "    def __len__(self): return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = [self.tok_src.word2idx[\"<sos>\"]] + self.tok_src.encode(self.src[idx]) + [self.tok_src.word2idx[\"<eos>\"]]\n",
    "        t = [self.tok_trg.word2idx[\"<sos>\"]] + self.tok_trg.encode(self.trg[idx]) + [self.tok_trg.word2idx[\"<eos>\"]]\n",
    "        return torch.tensor(s, dtype=torch.long), torch.tensor(t, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch, pad_idx=0):\n",
    "    src, trg = zip(*batch)\n",
    "    src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=pad_idx)\n",
    "    trg = nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=pad_idx)\n",
    "    return src, trg\n",
    "\n",
    "dataset = TranslationDataset(train_en, train_vi, tok_src, tok_trg)\n",
    "train_len = int(0.9 * len(dataset))\n",
    "val_len = len(dataset) - train_len\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_set, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ==============================\n",
    "# 5️⃣ POS ENCODING\n",
    "# ==============================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # registered buffer -> moves with .to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "# ==============================\n",
    "# 6️⃣ TRANSFORMER MODEL (with weight tying & device-safety)\n",
    "# ==============================\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model=256, nhead=4, num_layers=3, pad_idx=0, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.src_emb = nn.Embedding(src_vocab, d_model, padding_idx=pad_idx)\n",
    "        self.trg_emb = nn.Embedding(trg_vocab, d_model, padding_idx=pad_idx)\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, trg_vocab)\n",
    "        # weight tying (output projection shares embedding weight)\n",
    "        self.fc.weight = self.trg_emb.weight\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src: (B, S), trg: (B, T)\n",
    "        device = src.device\n",
    "        src_key_padding_mask = (src == self.pad_idx)  # (B, S)\n",
    "        trg_key_padding_mask = (trg == self.pad_idx)  # (B, T)\n",
    "        # subsequent mask for target (T, T)\n",
    "        T = trg.size(1)\n",
    "        trg_mask = nn.Transformer.generate_square_subsequent_mask(T).to(device)\n",
    "\n",
    "        src_emb = self.pos(self.src_emb(src))  # (B, S, d_model)\n",
    "        trg_emb = self.pos(self.trg_emb(trg))  # (B, T, d_model)\n",
    "\n",
    "        out = self.transformer(\n",
    "            src_emb, trg_emb,\n",
    "            tgt_mask=trg_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            tgt_key_padding_mask=trg_key_padding_mask,\n",
    "            memory_key_padding_mask=src_key_padding_mask\n",
    "        )  # (B, T, d_model)\n",
    "        return self.fc(out)  # (B, T, trg_vocab)\n",
    "\n",
    "# ==============================\n",
    "# 7️⃣ TRAINING FUNCTION (improvements: lr scheduler, AdamW, save best)\n",
    "# ==============================\n",
    "def train_model(model, train_loader, val_loader, device, epochs=10, lr=3e-4, pad_idx=0):\n",
    "    model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=1, factor=0.5, verbose=True)\n",
    "\n",
    "    best_val = float('inf')\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for src, trg in train_loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            opt.zero_grad()\n",
    "            # teacher forcing: feed trg tokens except last as input\n",
    "            out = model(src, trg[:, :-1])  # predict next token for each pos\n",
    "            # out: (B, T-1, V) -> flatten\n",
    "            loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:, 1:].reshape(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train = total_loss / len(train_loader)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for src, trg in val_loader:\n",
    "                src, trg = src.to(device), trg.to(device)\n",
    "                out = model(src, trg[:, :-1])\n",
    "                loss = loss_fn(out.reshape(-1, out.size(-1)), trg[:, 1:].reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "\n",
    "        scheduler.step(avg_val)\n",
    "\n",
    "        print(f\"Epoch {ep}/{epochs} | Train {avg_train:.4f} | Val {avg_val:.4f}\")\n",
    "\n",
    "        if avg_val < best_val:\n",
    "            best_val = avg_val\n",
    "            torch.save({\n",
    "                'model_state': model.state_dict(),\n",
    "                'tok_src': tok_src.word2idx,\n",
    "                'tok_trg': tok_trg.word2idx\n",
    "            }, \"best_model.pt\")\n",
    "            print(\"✔ Saved best model!\")\n",
    "\n",
    "# ==============================\n",
    "# 8️⃣ TRANSLATE (greedy) - improved (stop when <eos>, limit length)\n",
    "# ==============================\n",
    "def translate(model, text, tok_src, tok_trg, device, max_len=60):\n",
    "    model.eval()\n",
    "    src = [tok_src.word2idx[\"<sos>\"]] + tok_src.encode(text) + [tok_src.word2idx[\"<eos>\"]]\n",
    "    src = torch.tensor(src, dtype=torch.long).unsqueeze(0).to(device)  # (1, S)\n",
    "    trg = torch.tensor([[tok_trg.word2idx[\"<sos>\"]]], dtype=torch.long).to(device)  # (1,1)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            out = model(src, trg)  # (1, T, V)\n",
    "            next_tok = out[0, -1].argmax().item()\n",
    "            trg = torch.cat([trg, torch.tensor([[next_tok]], device=device)], dim=1)\n",
    "            if next_tok == tok_trg.word2idx[\"<eos>\"]:\n",
    "                break\n",
    "    # strip leading <sos> when decoding\n",
    "    return tok_trg.decode(trg[0].tolist()[1:])\n",
    "\n",
    "# ==============================\n",
    "# 9️⃣ EVALUATE BLEU (use smoothing)\n",
    "# ==============================\n",
    "def evaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=50):\n",
    "    model.eval()\n",
    "    total_bleu = 0\n",
    "    smooth = SmoothingFunction().method1\n",
    "    n = min(n, len(test_en))\n",
    "    for i in range(n):\n",
    "        pred = translate(model, test_en[i], tok_src, tok_trg, device)\n",
    "        bleu = sentence_bleu([test_vi[i].split()], pred.split(), smoothing_function=smooth)\n",
    "        total_bleu += bleu\n",
    "        if i < 10:  # print a few examples\n",
    "            print(f\"\\nEN: {test_en[i]}\")\n",
    "            print(f\"GT: {test_vi[i]}\")\n",
    "            print(f\"PR: {pred}\")\n",
    "            print(f\"BLEU: {bleu:.4f}\")\n",
    "\n",
    "    print(\"\\nAVERAGE BLEU =\", total_bleu / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2660bffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:56:44.142455Z",
     "iopub.status.busy": "2025-11-25T05:56:44.142127Z",
     "iopub.status.idle": "2025-11-25T07:32:40.771473Z",
     "shell.execute_reply": "2025-11-25T07:32:40.770724Z"
    },
    "papermill": {
     "duration": 5756.632899,
     "end_time": "2025-11-25T07:32:40.772740",
     "exception": false,
     "start_time": "2025-11-25T05:56:44.139841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train 7.0317 | Val 4.2933\n",
      "✔ Saved best model!\n",
      "Epoch 2/15 | Train 3.9949 | Val 3.5773\n",
      "✔ Saved best model!\n",
      "Epoch 3/15 | Train 3.4649 | Val 3.2186\n",
      "✔ Saved best model!\n",
      "Epoch 4/15 | Train 3.1537 | Val 2.9783\n",
      "✔ Saved best model!\n",
      "Epoch 5/15 | Train 2.9399 | Val 2.8171\n",
      "✔ Saved best model!\n",
      "Epoch 6/15 | Train 2.7756 | Val 2.7042\n",
      "✔ Saved best model!\n",
      "Epoch 7/15 | Train 2.6472 | Val 2.6203\n",
      "✔ Saved best model!\n",
      "Epoch 8/15 | Train 2.5423 | Val 2.5537\n",
      "✔ Saved best model!\n",
      "Epoch 9/15 | Train 2.4529 | Val 2.5009\n",
      "✔ Saved best model!\n",
      "Epoch 10/15 | Train 2.3783 | Val 2.4501\n",
      "✔ Saved best model!\n",
      "Epoch 11/15 | Train 2.3134 | Val 2.4152\n",
      "✔ Saved best model!\n",
      "Epoch 12/15 | Train 2.2537 | Val 2.3849\n",
      "✔ Saved best model!\n",
      "Epoch 13/15 | Train 2.2022 | Val 2.3647\n",
      "✔ Saved best model!\n",
      "Epoch 14/15 | Train 2.1551 | Val 2.3438\n",
      "✔ Saved best model!\n",
      "Epoch 15/15 | Train 2.1136 | Val 2.3305\n",
      "✔ Saved best model!\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# RUN (example)\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerModel(len(tok_src.word2idx), len(tok_trg.word2idx), d_model=256, nhead=4, num_layers=3, pad_idx=tok_src.word2idx[\"<pad>\"])\n",
    "train_model(model, train_loader, val_loader, device, epochs=15, lr=3e-4, pad_idx=tok_src.word2idx[\"<pad>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6843d53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:32:40.779520Z",
     "iopub.status.busy": "2025-11-25T07:32:40.779158Z",
     "iopub.status.idle": "2025-11-25T07:32:42.588901Z",
     "shell.execute_reply": "2025-11-25T07:32:42.588162Z"
    },
    "papermill": {
     "duration": 1.814537,
     "end_time": "2025-11-25T07:32:42.590185",
     "exception": false,
     "start_time": "2025-11-25T07:32:40.775648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN: When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;\n",
      "GT: Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;\n",
      "PR: khi tôi còn nhỏ , tôi nghĩ đất nước tôi là đất nước tốt nhất trên hành tinh , và tôi lớn lên một bài hát &quot; chẳng có gì để ghen tị . &quot;\n",
      "BLEU: 0.3277\n",
      "\n",
      "EN: And I was very proud .\n",
      "GT: Tôi đã rất tự hào về đất nước tôi .\n",
      "PR: và tôi rất tự hào .\n",
      "BLEU: 0.1179\n",
      "\n",
      "EN: In school , we spent a lot of time studying the history of Kim Il-Sung , but we never learned much about the outside world , except that America , South Korea , Japan are the enemies .\n",
      "GT: Ở trường , chúng tôi dành rất nhiều thời gian để học về cuộc đời của chủ tịch Kim II- Sung , nhưng lại không học nhiều về thế giới bên ngoài , ngoại trừ việc Hoa Kỳ , Hàn Quốc và Nhật Bản là kẻ thù của chúng tôi .\n",
      "PR: ở trường , chúng tôi dành rất nhiều thời gian nghiên cứu lịch sử kim tự nhiên , nhưng chúng tôi chưa bao giờ học được nhiều về thế giới bên ngoài , ngoại trừ nước mỹ , nhật bản là kẻ thù .\n",
      "BLEU: 0.3577\n",
      "\n",
      "EN: Although I often wondered about the outside world , I thought I would spend my entire life in North Korea , until everything suddenly changed .\n",
      "GT: Mặc dù tôi đã từng tự hỏi không biết thế giới bên ngoài kia như thế nào , nhưng tôi vẫn nghĩ rằng mình sẽ sống cả cuộc đời ở BắcTriều Tiên , cho tới khi tất cả mọi thứ đột nhiên thay đổi .\n",
      "PR: mặc dù tôi thường tự hỏi về thế giới bên ngoài , tôi nghĩ rằng tôi sẽ dành toàn bộ cuộc sống của mình ở bắc hàn quốc , cho đến khi mọi thứ đột nhiên thay đổi .\n",
      "BLEU: 0.2408\n",
      "\n",
      "EN: When I was seven years old , I saw my first public execution , but I thought my life in North Korea was normal .\n",
      "GT: Khi tôi lên 7 , tôi chứng kiến cảnh người ta xử bắn công khai lần đầu tiên trong đời , nhưng tôi vẫn nghĩ cuộc sống của mình ở đây là hoàn toàn bình thường .\n",
      "PR: khi tôi 7 tuổi , tôi thấy sự bùng phát đầu tiên của mình , nhưng tôi nghĩ cuộc sống của mình ở bắc hàn là bình thường .\n",
      "BLEU: 0.2163\n",
      "\n",
      "EN: My family was not poor , and myself , I had never experienced hunger .\n",
      "GT: Gia đình của tôi không nghèo , và bản thân tôi thì chưa từng phải chịu đói .\n",
      "PR: gia đình tôi không nghèo , và chính tôi , tôi chưa bao giờ trải qua nạn đói .\n",
      "BLEU: 0.2383\n",
      "\n",
      "EN: But one day , in 1995 , my mom brought home a letter from a coworker &apos;s sister .\n",
      "GT: Nhưng vào một ngày của năm 1995 , mẹ tôi mang về nhà một lá thư từ một người chị em cùng chỗ làm với mẹ .\n",
      "PR: nhưng một ngày , vào năm 1995 , mẹ tôi mang về nhà từ một người chị gái .\n",
      "BLEU: 0.3603\n",
      "\n",
      "EN: It read , &quot; When you read this , all five family members will not exist in this world , because we haven &apos;t eaten for the past two weeks .\n",
      "GT: Trong đó có viết : Khi chị đọc được những dòng này thì cả gia đình 5 người của em đã không còn trên cõi đời này nữa , bởi vì cả nhà em đã không có gì để ăn trong hai tuần .\n",
      "PR: nó đọc , &quot; khi bạn đọc nó , tất cả các thành viên gia đình sẽ không tồn tại trong thế giới này , bởi vì chúng ta chưa ăn trong vòng hai tuần .\n",
      "BLEU: 0.0470\n",
      "\n",
      "EN: We are lying on the floor together , and our bodies are so weak we are ready to die . &quot;\n",
      "GT: Tất cả cùng nằm trên sàn , và cơ thể chúng tôi yếu đến có thể cảm thấy như cái chết đang đến rất gần .\n",
      "PR: chúng ta nằm trên sàn nhà , và cơ thể chúng ta rất yếu để chúng ta sẵn sàng chết . &quot;\n",
      "BLEU: 0.1995\n",
      "\n",
      "EN: I was so shocked .\n",
      "GT: Tôi đã bị sốc .\n",
      "PR: tôi đã rất sốc .\n",
      "BLEU: 0.1257\n",
      "\n",
      "AVERAGE BLEU = 0.2231316714278509\n"
     ]
    }
   ],
   "source": [
    "evaluate_test_set(model, test_en, test_vi, tok_src, tok_trg, device, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97e1231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:32:42.597914Z",
     "iopub.status.busy": "2025-11-25T07:32:42.597697Z",
     "iopub.status.idle": "2025-11-25T07:32:42.641130Z",
     "shell.execute_reply": "2025-11-25T07:32:42.640482Z"
    },
    "papermill": {
     "duration": 0.048563,
     "end_time": "2025-11-25T07:32:42.642230",
     "exception": false,
     "start_time": "2025-11-25T07:32:42.593667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bạn thấy lần nữa .\n"
     ]
    }
   ],
   "source": [
    "sent = \"See you again\"\n",
    "print(translate(model, sent, tok_src, tok_trg, device))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8761788,
     "sourceId": 13767258,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 505429,
     "modelInstanceId": 489996,
     "sourceId": 649510,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5772.047984,
   "end_time": "2025-11-25T07:32:44.890813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T05:56:32.842829",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
